# Project File Organization Index
## Cross-Lingual Gender Bias Analysis in VLMs

**Last Updated**: January 2026

---

## Quick Navigation

| What You Need | Location |
|---------------|----------|
| **Three-Model Comparison** | `results/three_model_comparison/` |
| **Final Results Summary** | `results/qwen2vl_analysis/model_comparison_cosine.json` |
| **Main Comparison Figure** | `results/three_model_comparison/comprehensive_dashboard.png` |
| **Technical Report** | `results/TECHNICAL_REPORT.md` |
| **Probe Comparison** | `results/PROBE_COMPARISON_REPORT.md` |
| **Methodology Guide** | `docs/METHODOLOGY_VERIFICATION.md` |
| **Presentation** | `presentation/SUPERVISOR_PRESENTATION.md` |

---

## 1. Model Comparison Overview

### Models Analyzed
| Model | Parameters | Hidden Dim | Layers | SAE Features | Arabic Support |
|-------|------------|------------|--------|--------------|----------------|
| **PaLiGemma-3B** | 3B | 2,048 | 26 | 16,384 | Native multilingual |
| **Qwen2-VL-7B-Instruct** | 7B | 3,584 | 28 | 28,672 | Native Arabic tokens |
| **LLaVA-1.5-7B** | 7B | 4,096 | 32 | 32,768 | Byte-fallback (UTF-8) |

### Layers Analyzed
| PaLiGemma-3B | Qwen2-VL-7B | LLaVA-1.5-7B |
|--------------|-------------|--------------|
| 0, 3, 6, 9, 12, 15, 17 | 0, 4, 8, 12, 16, 20, 24, 27 | 0, 4, 8, 12, 16, 20, 24, 28, 31 |

---

## 2. File Organization by Model

### ğŸ“ PaLiGemma-3B Files

#### Checkpoints (Activations)
```
checkpoints/full_layers_ncc/
â”œâ”€â”€ layer_checkpoints/
â”‚   â”œâ”€â”€ layer_0_arabic.pt
â”‚   â”œâ”€â”€ layer_0_english.pt
â”‚   â”œâ”€â”€ layer_3_arabic.pt
â”‚   â”œâ”€â”€ layer_3_english.pt
â”‚   â”œâ”€â”€ layer_6_arabic.pt
â”‚   â”œâ”€â”€ layer_6_english.pt
â”‚   â”œâ”€â”€ layer_9_arabic.pt
â”‚   â”œâ”€â”€ layer_9_english.pt
â”‚   â”œâ”€â”€ layer_12_arabic.pt
â”‚   â”œâ”€â”€ layer_12_english.pt
â”‚   â”œâ”€â”€ layer_15_arabic.pt
â”‚   â”œâ”€â”€ layer_15_english.pt
â”‚   â”œâ”€â”€ layer_17_arabic.pt
â”‚   â””â”€â”€ layer_17_english.pt
```

#### SAE Models
```
checkpoints/saes/
â”œâ”€â”€ sae_layer_0.pt                    # Layer 0 (shared)
â”œâ”€â”€ sae_arabic_layer_3.pt             # Arabic SAEs
â”œâ”€â”€ sae_arabic_layer_6.pt
â”œâ”€â”€ sae_arabic_layer_9.pt
â”œâ”€â”€ sae_arabic_layer_12.pt
â”œâ”€â”€ sae_arabic_layer_15.pt
â”œâ”€â”€ sae_arabic_layer_17.pt
â”œâ”€â”€ sae_english_layer_3.pt            # English SAEs
â”œâ”€â”€ sae_english_layer_6.pt
â”œâ”€â”€ sae_english_layer_9.pt
â”œâ”€â”€ sae_english_layer_12.pt
â”œâ”€â”€ sae_english_layer_15.pt
â”œâ”€â”€ sae_english_layer_17.pt
â””â”€â”€ *_history.json                    # Training histories
```

#### Results
```
results/
â”œâ”€â”€ proper_cross_lingual/
â”‚   â””â”€â”€ cross_lingual_results.json    # â­ Main PaLiGemma results
â”œâ”€â”€ cross_lingual_overlap/
â”œâ”€â”€ sbi_analysis/
â”‚   â””â”€â”€ sbi_results.json              # Surgical Bias Intervention
â”œâ”€â”€ feature_stats_layer_*_arabic.csv  # Feature statistics
â”œâ”€â”€ feature_stats_layer_*_english.csv
â”œâ”€â”€ analysis_report.json
â””â”€â”€ ANALYSIS_REPORT.md
```

#### Visualizations
```
visualizations/
â”œâ”€â”€ proper_cross_lingual/             # â­ Cross-lingual analysis
â”‚   â”œâ”€â”€ summary.png                   # Overall comparison
â”‚   â”œâ”€â”€ layer_0_analysis.png
â”‚   â”œâ”€â”€ layer_3_analysis.png
â”‚   â”œâ”€â”€ layer_9_analysis.png
â”‚   â”œâ”€â”€ layer_12_analysis.png
â”‚   â”œâ”€â”€ layer_15_analysis.png
â”‚   â””â”€â”€ layer_17_analysis.png
â”œâ”€â”€ sample_predictions/               # Sample image predictions
â”‚   â”œâ”€â”€ layer_*_arabic/
â”‚   â”‚   â”œâ”€â”€ sample_grid.png
â”‚   â”‚   â””â”€â”€ misclassified_detail.png
â”‚   â””â”€â”€ layer_*_english/
â”‚       â”œâ”€â”€ sample_grid.png
â”‚       â””â”€â”€ misclassified_detail.png
â”œâ”€â”€ layer_*/                          # Per-layer analysis
â”‚   â”œâ”€â”€ tsne_gender.png
â”‚   â”œâ”€â”€ top_gender_features.png
â”‚   â””â”€â”€ feature_distributions.png
â”œâ”€â”€ cross_lingual/                    # CLBAS visualizations
â”‚   â”œâ”€â”€ layer_*_clbas.png
â”‚   â””â”€â”€ layer_*_comparison.png
â”œâ”€â”€ layer_comparison.png
â”œâ”€â”€ layer_comparison_arabic.png
â”œâ”€â”€ layer_comparison_english.png
â”œâ”€â”€ layer_heatmap.png
â”œâ”€â”€ layer_heatmap_arabic.png
â”œâ”€â”€ layer_heatmap_english.png
â””â”€â”€ accuracy_progression.png
```

---

### ğŸ“ Qwen2-VL-7B Files

#### Checkpoints (Activations)
```
checkpoints/qwen2vl/
â”œâ”€â”€ layer_checkpoints/
â”‚   â”œâ”€â”€ layer_0_arabic.pt
â”‚   â”œâ”€â”€ layer_0_english.pt
â”‚   â”œâ”€â”€ layer_4_arabic.pt
â”‚   â”œâ”€â”€ layer_4_english.pt
â”‚   â”œâ”€â”€ layer_8_arabic.pt
â”‚   â”œâ”€â”€ layer_8_english.pt
â”‚   â”œâ”€â”€ layer_12_arabic.pt
â”‚   â”œâ”€â”€ layer_12_english.pt
â”‚   â”œâ”€â”€ layer_16_arabic.pt
â”‚   â”œâ”€â”€ layer_16_english.pt
â”‚   â”œâ”€â”€ layer_20_arabic.pt
â”‚   â”œâ”€â”€ layer_20_english.pt
â”‚   â”œâ”€â”€ layer_24_arabic.pt
â”‚   â”œâ”€â”€ layer_24_english.pt
â”‚   â”œâ”€â”€ layer_27_arabic.pt
â”‚   â””â”€â”€ layer_27_english.pt
```

#### SAE Models
```
checkpoints/qwen2vl/saes/
â”œâ”€â”€ qwen2vl_sae_arabic_layer_0.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_4.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_8.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_12.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_16.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_20.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_24.pt
â”œâ”€â”€ qwen2vl_sae_arabic_layer_27.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_0.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_4.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_8.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_12.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_16.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_20.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_24.pt
â”œâ”€â”€ qwen2vl_sae_english_layer_27.pt
â””â”€â”€ *_history.json
```

#### Results
```
results/qwen2vl_analysis/
â”œâ”€â”€ model_comparison_cosine.json      # â­ Main comparison results
â”œâ”€â”€ model_comparison_results.json
â”œâ”€â”€ qwen2vl_analysis_results.json
â”œâ”€â”€ cosine_similarity_comparison.png  # â­ Key comparison figure
â”œâ”€â”€ final_model_comparison.png
â”œâ”€â”€ publication_summary.png
â”œâ”€â”€ qwen2vl_detailed_analysis.png
â”œâ”€â”€ qwen2vl_vs_paligemma_comparison.png
â””â”€â”€ qwen2vl_vs_paligemma_comparison.pdf
```

---

### ğŸ“ LLaVA-1.5-7B Files

#### Checkpoints (Activations)
```
checkpoints/llava/
â”œâ”€â”€ layer_checkpoints/
â”‚   â”œâ”€â”€ layer_0_arabic.pt
â”‚   â”œâ”€â”€ layer_0_english.pt
â”‚   â”œâ”€â”€ layer_4_arabic.pt
â”‚   â”œâ”€â”€ layer_4_english.pt
â”‚   â”œâ”€â”€ layer_8_arabic.pt
â”‚   â”œâ”€â”€ layer_8_english.pt
â”‚   â”œâ”€â”€ layer_12_arabic.pt
â”‚   â”œâ”€â”€ layer_12_english.pt
â”‚   â”œâ”€â”€ layer_16_arabic.pt
â”‚   â”œâ”€â”€ layer_16_english.pt
â”‚   â”œâ”€â”€ layer_20_arabic.pt
â”‚   â”œâ”€â”€ layer_20_english.pt
â”‚   â”œâ”€â”€ layer_24_arabic.pt
â”‚   â”œâ”€â”€ layer_24_english.pt
â”‚   â”œâ”€â”€ layer_28_arabic.pt
â”‚   â”œâ”€â”€ layer_28_english.pt
â”‚   â”œâ”€â”€ layer_31_arabic.pt
â”‚   â””â”€â”€ layer_31_english.pt
```

#### SAE Models
```
checkpoints/llava/saes/
â”œâ”€â”€ llava_sae_arabic_layer_0.pt
â”œâ”€â”€ llava_sae_arabic_layer_4.pt
â”œâ”€â”€ llava_sae_arabic_layer_8.pt
â”œâ”€â”€ llava_sae_arabic_layer_12.pt
â”œâ”€â”€ llava_sae_arabic_layer_16.pt
â”œâ”€â”€ llava_sae_arabic_layer_20.pt
â”œâ”€â”€ llava_sae_arabic_layer_24.pt
â”œâ”€â”€ llava_sae_arabic_layer_28.pt
â”œâ”€â”€ llava_sae_arabic_layer_31.pt
â”œâ”€â”€ llava_sae_english_layer_0.pt
â”œâ”€â”€ llava_sae_english_layer_4.pt
â”œâ”€â”€ llava_sae_english_layer_8.pt
â”œâ”€â”€ llava_sae_english_layer_12.pt
â”œâ”€â”€ llava_sae_english_layer_16.pt
â”œâ”€â”€ llava_sae_english_layer_20.pt
â”œâ”€â”€ llava_sae_english_layer_24.pt
â”œâ”€â”€ llava_sae_english_layer_28.pt
â”œâ”€â”€ llava_sae_english_layer_31.pt
â””â”€â”€ *_history.json
```

#### Results
```
results/llava_analysis/
â”œâ”€â”€ cross_lingual_results.json        # Main LLaVA results
â”œâ”€â”€ feature_overlap_results.json
â”œâ”€â”€ probe_results.json
â”œâ”€â”€ llava_analysis_summary.png
â””â”€â”€ layer_*_analysis.png
```

---

### ğŸ“ Three-Model Comparison

#### Results
```
results/three_model_comparison/
â”œâ”€â”€ comparison_report.md              # â­ Markdown report
â”œâ”€â”€ combined_metrics.csv              # All metrics in CSV
â”œâ”€â”€ summary_statistics.json           # Statistical summaries
â”œâ”€â”€ comprehensive_dashboard.png       # â­ Main comparison figure
â”œâ”€â”€ comprehensive_dashboard.pdf
â”œâ”€â”€ clbas_comparison.png
â”œâ”€â”€ clbas_comparison.pdf
â”œâ”€â”€ probe_accuracy_comparison.png
â”œâ”€â”€ probe_accuracy_comparison.pdf
â”œâ”€â”€ layer_position_heatmap.png
â””â”€â”€ layer_position_heatmap.pdf
```

---

## 3. Scripts by Model

### PaLiGemma-3B Pipeline
```
scripts/
â”œâ”€â”€ 01_prepare_data.py               # Data preparation
â”œâ”€â”€ 02_extract_activations.py        # Activation extraction
â”œâ”€â”€ 03_train_sae.py                  # SAE training
â”œâ”€â”€ 23_proper_cross_lingual_analysis.py  # Cross-lingual analysis
â”œâ”€â”€ 24_cross_lingual_overlap.py      # Feature overlap
â”œâ”€â”€ 26_surgical_bias_intervention.py # SBI analysis
â””â”€â”€ 27_statistical_significance.py   # Statistical tests
```

### Qwen2-VL-7B Pipeline
```
scripts/
â”œâ”€â”€ 28_extract_qwen2vl_activations.py    # Activation extraction
â”œâ”€â”€ 29_train_qwen2vl_sae.py              # SAE training
â”œâ”€â”€ 30_qwen2vl_cross_lingual_analysis.py # Cross-lingual analysis
â”œâ”€â”€ 31_qwen2vl_comprehensive_analysis.py # Full analysis
â””â”€â”€ 32_generate_qwen2vl_visualizations.py # Visualizations
```

### LLaVA-1.5-7B Pipeline
```
scripts/
â”œâ”€â”€ 33_llava_extract_activations.py      # Activation extraction (Arabic via byte-fallback)
â”œâ”€â”€ 34_llava_train_sae.py                # SAE training (d=4096 â†’ 32,768 features)
â”œâ”€â”€ 35_llava_cross_lingual_analysis.py   # Cross-lingual analysis
â””â”€â”€ slurm_33_llava_extract.sh            # SLURM array job for extraction
â”œâ”€â”€ slurm_34_llava_sae.sh                # SLURM array job for SAE training
â”œâ”€â”€ slurm_35_llava_analysis.sh           # SLURM job for analysis
â””â”€â”€ slurm_llava_full_pipeline.sh         # Full sequential pipeline
```

### Three-Model Comparison
```
scripts/
â””â”€â”€ 37_three_model_comparison.py         # â­ Comprehensive 3-model analysis
```

---

## 4. Key Results Files

### â­ Most Important Files

| File | Description |
|------|-------------|
| `results/three_model_comparison/comprehensive_dashboard.png` | Three-model comparison figure |
| `results/three_model_comparison/comparison_report.md` | Full comparison report |
| `results/qwen2vl_analysis/model_comparison_cosine.json` | PaLiGemma vs Qwen2-VL data |
| `results/proper_cross_lingual/cross_lingual_results.json` | PaLiGemma detailed results |
| `results/llava_analysis/cross_lingual_results.json` | LLaVA detailed results |
| `results/sbi_analysis/sbi_results.json` | Surgical intervention results |
| `results/PROBE_COMPARISON_REPORT.md` | Probe accuracy comparison |
| `docs/METHODOLOGY_VERIFICATION.md` | Full methodology documentation |

### Key Figures

| Figure | Location | Description |
|--------|----------|-------------|
| 3-Model Dashboard | `results/three_model_comparison/comprehensive_dashboard.png` | â­ Main comparison |
| CLBAS Comparison | `results/three_model_comparison/clbas_comparison.png` | Cross-lingual scores |
| Probe Accuracy | `results/three_model_comparison/probe_accuracy_comparison.png` | Gender probes |
| Layer Heatmap | `results/three_model_comparison/layer_position_heatmap.png` | By layer depth |
| Model Comparison | `results/qwen2vl_analysis/cosine_similarity_comparison.png` | PaLiGemma vs Qwen2-VL |
| PaLiGemma Summary | `visualizations/proper_cross_lingual/summary.png` | Layer-wise comparison |
| Sample Predictions | `visualizations/sample_predictions/layer_3_arabic/sample_grid.png` | Example predictions |

---

## 5. Results Summary

### Three-Model Comparison

| Model | Arabic Support | Mean CLBAS | Probe Gap | SAE Features |
|-------|----------------|------------|-----------|--------------|
| PaLiGemma-3B | Native multilingual | ~0.027 | AR+3.3% | 16,384 |
| Qwen2-VL-7B | Native Arabic tokens | ~0.004 | EN+1.5% | 28,672 |
| LLaVA-1.5-7B | Byte-fallback (UTF-8) | TBD | TBD | 32,768 |

### Cosine Similarity (Cross-Lingual Alignment)

| Model | Mean | Max | Interpretation |
|-------|------|-----|----------------|
| PaLiGemma-3B | **0.027** | 0.041 | Low alignment |
| Qwen2-VL-7B | **0.004** | 0.008 | Very low alignment |
| LLaVA-1.5-7B | TBD | TBD | TBD |
| **Ratio** | 6.7Ã— | - | Larger model = more specific |

### Probe Accuracy

| Model | Arabic | English | Higher |
|-------|--------|---------|--------|
| PaLiGemma-3B | **0.886** | 0.853 | Arabic +3.3% |
| Qwen2-VL-7B | 0.903 | **0.918** | English +1.5% |
| LLaVA-1.5-7B | TBD | TBD | TBD |

### Feature Overlap

| Model | Overlap Count | Jaccard |
|-------|---------------|---------|
| PaLiGemma-3B | 3 | ~0.015 |
| Qwen2-VL-7B | 1 | ~0.005 |
| LLaVA-1.5-7B | TBD | TBD |

---

## 6. Documentation Files

```
docs/
â”œâ”€â”€ METHODOLOGY_VERIFICATION.md      # â­ Full methodology
â”œâ”€â”€ CLMB_FRAMEWORK.md
â”œâ”€â”€ DURHAM_NCC_GUIDE.md
â””â”€â”€ NCC_EXTRACTION_GUIDE.md

presentation/
â”œâ”€â”€ SUPERVISOR_PRESENTATION.md       # â­ Presentation slides
â”œâ”€â”€ COSINE_SIMILARITY_DEFENSE.md     # Literature defense
â””â”€â”€ figures/

results/
â”œâ”€â”€ PROBE_COMPARISON_REPORT.md       # â­ Probe comparison
â”œâ”€â”€ COSINE_SIMILARITY_ANALYSIS.md
â”œâ”€â”€ TECHNICAL_REPORT.md
â””â”€â”€ ANALYSIS_REPORT.md
```

---

## 7. Quick Commands

### View key results
```bash
# Three-model comparison
cat results/three_model_comparison/comparison_report.md

# PaLiGemma results
cat results/proper_cross_lingual/cross_lingual_results.json | python -m json.tool | head -50

# Model comparison
cat results/qwen2vl_analysis/model_comparison_cosine.json | python -m json.tool

# LLaVA results
cat results/llava_analysis/cross_lingual_results.json | python -m json.tool | head -50

# SBI results
cat results/sbi_analysis/sbi_results.json | python -m json.tool | head -50
```

### Check file sizes
```bash
# SAE model sizes
du -sh checkpoints/saes/*.pt
du -sh checkpoints/qwen2vl/saes/*.pt
du -sh checkpoints/llava/saes/*.pt
```

### Run pipelines
```bash
# LLaVA full pipeline
sbatch scripts/slurm_llava_full_pipeline.sh

# Or individual steps:
sbatch scripts/slurm_33_llava_extract.sh   # Array job: 0=arabic, 1=english
sbatch scripts/slurm_34_llava_sae.sh       # Array job: 0-17 (9 layers Ã— 2 langs)
sbatch scripts/slurm_35_llava_analysis.sh  # Cross-lingual analysis

# Three-model comparison
python scripts/37_three_model_comparison.py
```

---

*This index provides a complete map of all files for PaLiGemma-3B, Qwen2-VL-7B, and LLaVA-1.5-7B analysis.*
