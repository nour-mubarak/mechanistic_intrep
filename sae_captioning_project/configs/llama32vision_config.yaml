
# Llama 3.2 Vision (11B) Configuration
# =====================================
# Cross-lingual gender bias analysis configuration

model:
  name: "Llama-3.2-Vision-11B"
  id: "meta-llama/Llama-3.2-11B-Vision-Instruct"
  hidden_size: 4096
  num_layers: 40
  vocab_size: 128256
  arabic_support: "native"  # Native multilingual training

sae:
  expansion_factor: 8
  num_features: 32768  # 4096 * 8
  l1_coefficient: 0.0001
  learning_rate: 0.001
  epochs: 50
  batch_size: 256

extraction:
  layers: [0, 5, 10, 15, 20, 25, 30, 35, 39]
  checkpoint_interval: 50
  dtype: "bfloat16"

analysis:
  top_k_features: 100
  probe_cv_folds: 5

data:
  samples_file: "data/processed/samples.csv"
  images_dir: "data/raw/images"

output:
  checkpoints_dir: "checkpoints/llama32vision"
  results_dir: "results/llama32vision_analysis"

wandb:
  project: "llama32vision-sae-analysis"
  entity: "nourmubarak"

# Hardware requirements
requirements:
  gpu_memory: "80GB"  # A100 recommended for 11B model
  cpu_memory: "128GB"
  estimated_runtime: "24-48 hours"
